{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import os.path\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "import datetime\n",
    "\n",
    "base_url = 'https://comtrade.un.org/api/get?'\n",
    "\n",
    "def mk_slice_points(reporter,partner,period,human_readable=False,product='all',frequency='A'):\n",
    "\n",
    "    # (2) warn/ raise an error if appropriate\n",
    "\n",
    "    if sum('all' in inpt for inpt in [reporter, partner, period]) > 1:\n",
    "        raise ValueError(\"Only one of the parameters 'reporter', 'partner' and 'period' may use the special ALL value in a given API call.\")\n",
    "\n",
    "    if any(len(inpt) > 5 for inpt in [reporter, partner, period]) and human_readable:\n",
    "        print(\"Using the option human_readable=True is not recommended in this case because several API calls are necessary.\")\n",
    "        print(\"When using the human_readable=True option, messages from the API cannot be received!\")\n",
    "        response = input(\"Press y if you want to continue anyways. \")\n",
    "        if response != 'y':\n",
    "            return None # exit function\n",
    "\n",
    "    slice_points = [range(0, len(inpt), 5) for inpt in [reporter, partner, period]] + \\\n",
    "        [range(0, len(product), 20)]  \n",
    "    \n",
    "    return slice_points\n",
    "\n",
    "def download_trade_data(filename, human_readable=False, verbose=True,\n",
    "    period='recent', frequency='A', reporter='USA', partner='all', product='total', tradeflow='exports'):\n",
    "\n",
    "    \"\"\"\n",
    "    Downloads records from the UN Comtrade database and saves them in a csv-file with the name \"filename\".\n",
    "    If necessary, it calls the API several times.\n",
    "    There are two modes:\n",
    "    - human_readable = False (default): headings in output are not human-readable but error messages from the API are received and displayed\n",
    "    - human_readable = True: headings in output are human-readable but we do not get messages from the API about potential problems (not recommended if several API calls are necessary)\n",
    "    Additional option: verbose = False in order to suppress both messages from the API and messages like '100 records downloaded and saved in filename.csv' (True is default)\n",
    "    Parameters:\n",
    "    Using parameter values suggested in the API documentation should always work.\n",
    "    For the parameters period, reporter, partner and tradeflow more intuitive options have been added.\n",
    "     - period     [ps]   : depending on freq, either YYYY or YYYYMM (or 'YYYY-YYYY'/ 'YYYYMM-YYYYMM' or a list of those) or 'now' or 'recent' (= 5 most recent years/ months) or 'all'\n",
    "     - frequency  [freq] : 'A' (= annual) or 'M' (= monthly)\n",
    "     - reporter   [r]    : reporter code/ name (case-sensitive!) or list of reporter codes/ names or 'all' (see https://comtrade.un.org/data/cache/reporterAreas.json)\n",
    "     - partner    [p]    : partner code/ name  (case-sensitive!) or list of partner codes/ names or 'all' (see https://comtrade.un.org/data/cache/partnerAreas.json)\n",
    "     - product    [cc]   : commodity code valid in the selected classification (here: Harmonized System HS) or 'total' (= aggregated) or 'all' or 'HG2', 'HG4' or 'HG6' (= all 2-, 4- and 6-digit HS commodities)\n",
    "     - tradeflow  [rg]   : 'import[s]' or 'export[s]'; see https://comtrade.un.org/data/cache/tradeRegimes.json for further, lower-level options\n",
    "     Information copied from the API Documentation (https://comtrade.un.org/data/doc/api/):\n",
    "     Usage limits\n",
    "     Rate limit (guest): 1 request every second (per IP address or authenticated user).\n",
    "     Usage limit (guest): 100 requests per hour (per IP address or authenticated user).\n",
    "     Parameter combination limit: ps, r and p are limited to 5 codes each. Only one of the above codes may use the special ALL value in a given API call.\n",
    "     Classification codes (cc) are limited to 20 items. ALL is always a valid classification code.\n",
    "     If you hit a usage limit a 409 (conflict) error is returned along with a message specifying why the request was blocked and when requests may resume.\n",
    "     Stability\n",
    "     Notice: this API may be considered stable. However, new fields may be added in the future.\n",
    "     While this API is still subject to change, changes that remove fields will be announced and a method of accessing legacy field formats will be made available during a transition period.\n",
    "     New fields may be added to the CSV or JSON output formats without warning. Please write your code that accesses the API accordingly.\n",
    "     \"\"\"\n",
    "    reporter = transform_reporter(reporter)\n",
    "    partner = transform_partner(partner)\n",
    "    period = transform_period(period, frequency)\n",
    "    \n",
    "    slice_points = mk_slice_points(reporter,partner,period,human_readable)\n",
    "        \n",
    "    # (3) download data by doing one or several API calls\n",
    "\n",
    "\n",
    "    # since the parameters reporter, partner and period are limited to 5 inputs each and\n",
    "    # product is limited to 20 inputs\n",
    "    \n",
    "    tradeflow = transform_tradeflow(tradeflow)\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    slices = itertools.product(*slice_points)\n",
    "    r = 0 \n",
    "    for i, j, k, m in slices:\n",
    "\n",
    "        df = download_trade_data_base(human_readable=human_readable, verbose=verbose,\n",
    "            period=period[k:k+5], reporter=reporter[i:i+5],\n",
    "            partner=partner[j:j+5], product=product[m:m+20],\n",
    "            tradeflow=tradeflow, frequency=frequency,filename=filename )\n",
    "        r += 1\n",
    "\n",
    "        if df is not None:\n",
    "            dfs.append(df)\n",
    "\n",
    "        sleep(1) # wait 1 second because of API rate limit\n",
    "\n",
    "    # (4) save dataframe as csv file\n",
    "\n",
    "    if len(dfs) > 0:\n",
    "        df_all = pd.concat(dfs)\n",
    "        filename = filename if len(filename.split('.')) >= 2 else filename + '.csv' # add '.csv' if necessary\n",
    "        df_all.to_csv(filename)\n",
    "        if verbose: print('{} records downloaded and saved as {}.'.format(len(df_all), filename))\n",
    "            \n",
    "    return (r)\n",
    "\n",
    "def download_trade_data_base(human_readable=False, verbose=True,\n",
    "    period='recent', frequency='A', reporter=842, partner='all', product='total', tradeflow=2,filename=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Downloads records from the UN Comtrade database and returns pandas dataframe using one API call.\n",
    "    There are two modes:\n",
    "    - human_readable = False (default): headings in output are not human-readable but error messages from the API are received and displayed\n",
    "    - human_readable = True: headings in output are human-readable but we do not get messages from the API about potential problems\n",
    "    Additional option: verbose = False in order to suppress messages from the API (True is default)\n",
    "    Parameters of the API call:\n",
    "    As documented in the API documentation.\n",
    "    More intuitive options for the parameters period, reporter, partner and tradeflow are only available in the function 'download_trade_data'!\n",
    "     - period     [ps]   : depending on freq, either YYYY or YYYYMM (or a list of those) or 'now' or 'recent' (= 5 most recent years/ months) or 'all'\n",
    "     - frequency  [freq] : 'A' (= annual) or 'M' (= monthly)\n",
    "     - reporter   [r]    : reporter code or list of reporter codes or 'all' (see https://comtrade.un.org/data/cache/reporterAreas.json)\n",
    "     - partner    [p]    : partner code or list of partner codes or 'all' (see https://comtrade.un.org/data/cache/partnerAreas.json)\n",
    "     - product    [cc]   : commodity code valid in the selected classification (here: Harmonized System HS) or 'total' (= aggregated) or 'all' or 'HG2', 'HG4' or 'HG6' (= all 2-, 4- and 6-digit HS commodities)\n",
    "     - tradeflow  [rg]   : 1 (for imports) or 2 (for exports); see https://comtrade.un.org/data/cache/tradeRegimes.json for further options\n",
    "    \"\"\"\n",
    "\n",
    "    fmt = 'csv' if human_readable else 'json'\n",
    "    head = 'H' if human_readable else 'M'\n",
    "\n",
    "    parameters = {\n",
    "        'ps': period,\n",
    "        'freq': frequency,\n",
    "        'r': reporter,\n",
    "        'p': partner,\n",
    "        'cc': product,\n",
    "        'rg': tradeflow,\n",
    "        'px': 'HS',      # Harmonized System (as reported) as classification scheme\n",
    "        'type': 'C',     # Commodities ('S' for Services)\n",
    "        'fmt': fmt,      # format of the output\n",
    "        'max': 100000,    # maximum number of rows -> what happens if number of rows is bigger?\n",
    "                         # https://comtrade.un.org/data/dev/portal#subscription says it is 100 000\n",
    "        'head': head     # human readable headings ('H') or machine readable headings ('M')\n",
    "    }\n",
    "\n",
    "    url = base_url + dict_to_string(parameters)\n",
    "\n",
    "    if verbose: print(url)\n",
    "\n",
    "    if human_readable:\n",
    "\n",
    "        dataframe = pd.read_csv(url)\n",
    "\n",
    "    else:\n",
    "\n",
    "        json_dict = requests.get(url,timeout=120).json()\n",
    "\n",
    "        n_records = json_dict['validation']['count']['value']\n",
    "        message = json_dict['validation']['message']\n",
    "\n",
    "        if not json_dict['dataset']:\n",
    "            if verbose: print('Error: empty dataset \\n Message: {}'.format(message))\n",
    "            dataframe = None\n",
    "            f = open(filename,\"w+\")\n",
    "            f.close()\n",
    "\n",
    "        else:\n",
    "            if verbose and message: print('Message: {}'.format(message))\n",
    "            dataframe = pd.DataFrame.from_dict(json_dict['dataset'])\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def transform_reporter(reporter):\n",
    "    \"\"\"\n",
    "    replaces country names in reporter by the corresponding country codes\n",
    "    \"\"\"\n",
    "    # if single country code/ name, convert to list\n",
    "    reporter = [reporter] if not isinstance(reporter, list) else reporter\n",
    "    # replace country names by country codes\n",
    "    reporter = [r if is_country_code(r) else find_reporter_code(r) for r in reporter]\n",
    "    return reporter\n",
    "\n",
    "\n",
    "def transform_partner(partner):\n",
    "    \"\"\"\n",
    "    replaces country names in partner by the corresponding country codes\n",
    "    \"\"\"\n",
    "    # if single country code/ name, convert to list\n",
    "    partner = [partner] if not isinstance(partner, list) else partner\n",
    "    # replace country names by country codes\n",
    "    partner = [p if is_country_code(p) else find_partner_code(p) for p in partner]\n",
    "    return partner\n",
    "\n",
    "\n",
    "def transform_tradeflow(tradeflow):\n",
    "    \"\"\"\n",
    "    replace tradeflow \"import(s)\" or \"export(s)\" by the corresponding numbers (1 / 2)\n",
    "    \"\"\"\n",
    "    if isinstance(tradeflow, str):\n",
    "        if 'export' in tradeflow.lower():\n",
    "            tradeflow = 2\n",
    "        elif 'import' in tradeflow.lower():\n",
    "            tradeflow = 1\n",
    "    return tradeflow\n",
    "\n",
    "\n",
    "def transform_period(period, frequency):\n",
    "    \"\"\"\n",
    "    detects 'YYYY-YYYY' or 'YYYYMM-YYYYMM' inputs and transforms them into lists of YYYY or YYYYMM that the API can understand\n",
    "    the function does not check whether the other inputs for period are valid!\n",
    "    period: depending on freq, either YYYY or YYYYMM (or 'YYYY-YYYY'/ 'YYYYMM-YYYYMM' or a list of those) or 'now' or 'recent' or 'all'\n",
    "    frequency: 'A' or 'M'\n",
    "    \"\"\"\n",
    "\n",
    "    period = [period] if not isinstance(period, list) else period\n",
    "\n",
    "    period_new = []\n",
    "\n",
    "    for p in period:\n",
    "\n",
    "        if isinstance(p, str) and '-' in p:\n",
    "            start, end = p.split('-')\n",
    "\n",
    "            if frequency.lower() == 'a':\n",
    "                y_start = int(start)\n",
    "                y_end = int(end)\n",
    "                for y in range(y_start, y_end + 1):\n",
    "                    period_new.append(y)\n",
    "\n",
    "            elif frequency.lower() == 'm':\n",
    "                y_start, m_start = int(start[:4]), int(start[4:])\n",
    "                y_end, m_end = int(end[:4]), int(end[4:])\n",
    "                n = (m_end - m_start + 1) + 12 * (y_end - y_start)\n",
    "                y, m = y_start, m_start\n",
    "                for _ in range(n):\n",
    "                    period_new.append('{}{:02d}'.format(y, m))\n",
    "                    if m >= 1 and m < 12:\n",
    "                        m +=1\n",
    "                    elif m == 12:\n",
    "                        m = 1\n",
    "                        y += 1\n",
    "                    else:\n",
    "                        raise Exception(\"Shouldn't get here.\")\n",
    "\n",
    "            else:\n",
    "                raise Exception(\"Frequency neither 'A'/'a' nor 'M'/'m'.\")\n",
    "\n",
    "        else:\n",
    "            period_new.append(p)\n",
    "\n",
    "    return period_new\n",
    "\n",
    "\n",
    "def is_country_code(inpt):\n",
    "    \"\"\"\n",
    "    checks if inpt is a valid country code, i.e. an integer, an integer converted to a string or 'all'\n",
    "    output: True or False\n",
    "    \"\"\"\n",
    "    if isinstance(inpt, str):\n",
    "        return inpt.lower() == 'all' or inpt.isdigit()\n",
    "    else:\n",
    "        return isinstance(inpt, int) or isinstance(inpt, np.int64)\n",
    "\n",
    "\n",
    "def find_reporter_code(country):\n",
    "    \"\"\"\n",
    "    see 'find_country_code'\n",
    "    \"\"\"\n",
    "    return find_country_code(country, 'reporter')\n",
    "\n",
    "\n",
    "def find_partner_code(country):\n",
    "    \"\"\"\n",
    "    see 'find_country_code'\n",
    "    \"\"\"\n",
    "    return find_country_code(country, 'partner')\n",
    "\n",
    "\n",
    "def find_country_code(country, reporter_or_partner):\n",
    "    \"\"\"\n",
    "    tries to find the country code corresponding to a country name\n",
    "    procedure: try to find exact match, if not look for partial matches\n",
    "    input country: country name or part of country name (case-sensitive!)\n",
    "    input reporter_or_partner: 'reporter' or 'partner'\n",
    "    output: country code\n",
    "    \"\"\"\n",
    "\n",
    "    # we use a local copy of the file with country codes so that we do not have to use\n",
    "    # https://comtrade.un.org/data/cache/reporterAreas.json every time\n",
    "    if not os.path.exists(reporter_or_partner + 'Areas.csv'):\n",
    "        download_country_codes_file(reporter_or_partner)\n",
    "    df = pd.read_csv(reporter_or_partner + 'Areas.csv', encoding='latin_1', index_col=0)\n",
    "\n",
    "    # look for an exact match\n",
    "    mask = (df.text == country)\n",
    "    if sum(mask) == 1:\n",
    "        code = df.index[mask].tolist()[0]\n",
    "        return code\n",
    "\n",
    "    # look for a partial match\n",
    "    # this might be useful because some 'official' names of countries are not always that well-known\n",
    "    # e.g. 'Bolivia (Plurinational State of)' instead of Bolivia'\n",
    "    mask2 = (df.text.str.contains(country))\n",
    "    if sum(mask2) > 0:\n",
    "        print('There is no country in the json-file with the exact name \"{}\". '.format(country) + \\\n",
    "            'The following countries contain the word \"{}\". '.format(country) + \\\n",
    "            'If you think that one of the following countries is the one that you are looking for, press \"y\".')\n",
    "        dict_matches = df[mask2].text.to_dict()\n",
    "        for code, country in dict_matches.items():\n",
    "            response = input('{} {} [y?] '.format(code, country))\n",
    "            if response == 'y':\n",
    "                return code\n",
    "\n",
    "    # if no code could be found:\n",
    "    raise LookupError('It was not possible to find a code that corresponds to the country {}.'.format(country))\n",
    "\n",
    "\n",
    "def download_country_codes_file(reporter_or_partner):\n",
    "    \"\"\"\n",
    "    downloads either the reporter or the partner file and saves it in the current directory\n",
    "    input: 'reporter' or 'partner'\n",
    "    \"\"\"\n",
    "    url = 'https://comtrade.un.org/data/cache/{}Areas.json'.format(reporter_or_partner)\n",
    "    json_dict = requests.get(url).json()\n",
    "    df = pd.DataFrame.from_dict(json_dict['results'])\n",
    "    df = df.set_index('id')\n",
    "    df.drop('all', inplace=True)\n",
    "    df.to_csv('{}Areas.csv'.format(reporter_or_partner))\n",
    "\n",
    "def dict_item_to_string(key, value):\n",
    "    \"\"\"\n",
    "    inputs: key-value pairs from a dictionary\n",
    "    output: string 'key=value' or 'key=value1,value2' (if value is a list)\n",
    "    examples: 'fmt', 'csv' => 'fmt=csv' or 'r', [124, 484] => 'r=124,484'\n",
    "    \"\"\"\n",
    "    value_string = str(value) if not isinstance(value, list) else ','.join(map(str, value))\n",
    "    return '='.join([key, value_string])\n",
    "\n",
    "\n",
    "def dict_to_string(parameters):\n",
    "    \"\"\"\n",
    "    input: dictionary of parameters\n",
    "    output: string 'key1=value1&key2=value2&...'\n",
    "    \"\"\"\n",
    "    return '&'.join(dict_item_to_string(key, value) for key, value in parameters.items())\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def product_codes_with_parent(parent_code):\n",
    "    \"\"\"\n",
    "    Returns a python dictionary with all entries that belong to parent_code.\n",
    "    \"\"\"\n",
    "    if not os.path.exists('classificationHS.csv'):\n",
    "        download_product_codes_file()\n",
    "    df = load_product_codes_file()\n",
    "    mask = df.parent == parent_code\n",
    "    return df.text[mask].to_dict()\n",
    "\n",
    "def search_product_code(pat, case=True, flags=0, regex=True, n_digits=None):\n",
    "    \"\"\"\n",
    "    Returns a python dictionary with all entries that contain the pattern pat and have a code with length n_digits.\n",
    "    If n_digits = None (default), we do not care about how many digits the classification code has.\n",
    "    For searching for the pattern pat, we use pd.Series.str.contains which takes the following parameters:\n",
    "    pat : string\n",
    "        Character sequence or regular expression\n",
    "    case : boolean, default True\n",
    "        If True, case sensitive\n",
    "    flags : int, default 0 (no flags)\n",
    "        re module flags, e.g. re.IGNORECASE\n",
    "    regex : bool, default True\n",
    "        If True use re.search, otherwise use Python in operator\n",
    "    \"\"\"\n",
    "    if not os.path.exists('classificationHS.csv'):\n",
    "        download_product_codes_file()\n",
    "    df = load_product_codes_file()\n",
    "    if n_digits is not None:\n",
    "        mask1 = df.text.str.contains(pat, case=case, flags=flags, regex=regex)\n",
    "        mask2 = df.index.to_series().apply(lambda digit: len(digit) == n_digits)\n",
    "        mask = mask1 & mask2\n",
    "    else: mask = df.text.str.contains(pat, case=case, flags=flags, regex=regex)\n",
    "    return df.text[mask].to_dict()\n",
    "\n",
    "\n",
    "def load_product_codes_file():\n",
    "    \"\"\"\n",
    "    Loads the product codes file as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('classificationHS.csv', encoding='latin-1', index_col='id')\n",
    "    return df\n",
    "\n",
    "\n",
    "def download_product_codes_file():\n",
    "    \"\"\"\n",
    "    Downloads the product codes files and saves it in the current directory.\n",
    "    The short-cut entries for 'ALL', 'TOTAL', 'AG2', 'AG4' and 'AG6' are deleted.\n",
    "    \"\"\"\n",
    "    url = 'https://comtrade.un.org/data/cache/classificationHS.json'\n",
    "    json_dict = requests.get(url).json()\n",
    "    df = pd.DataFrame.from_dict(json_dict['results'])\n",
    "    df = df.set_index('id')\n",
    "    df.drop(['ALL', 'TOTAL', 'AG2', 'AG4', 'AG6'], inplace=True)\n",
    "    df.text = df.text.apply(lambda x: ' - '.join(x.split(' - ')[1:])) # remove digits from beginning of text\n",
    "    df.to_csv('classificationHS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporters = ['Greece','Armenia','Turkey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_flows = ['all']\n",
    "# periods = ['201001-201005','201006-201010','201011-201103','201104-201108','201109-201201','201202-201206',\n",
    "#            '201207-201211','201212-201304','201305-201309','201310-201312']\n",
    "  periods = ['201801-201805']\n",
    "# periods = ['201401-201405','201406-201410','201411-201503','201504-201508','201509-201601','201602-201606',\n",
    "#            '201607-201611','201612-201704','201705-201709','201710-201712','201801-201805','201806-201810',\n",
    "#            '201811-201812','201001-201005','201006-201010','201011-201103','201104-201108','201109-201201',\n",
    "#            '201202-201206','201207-201211','201212-201304','201305-201309','201310-201312']\n",
    
    "# periods = ['201001-201005','201006-201010','201011-201103','201104-201108','201109-201201',\n",
    "#           '201202-201206','201207-201211','201212-201304','201305-201309','201310-201312',\n",
    "#           '201401-201405','201406-201410','201411-201503','201504-201508','201509-201601','201602-201606',\n",
    "#           '201607-201611','201612-201704','201705-201709','201710-201712','201801-201805','201806-201810',\n",
    "#           '201811-201812','201901-201905','201906-201910','201911-201912','202001-202005','202006-202010','202011-202012']\n",
    "periods.reverse()\n",
    "partners = [\"Saudi Arabia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporters= pd.read_csv(\"reporterAreas.csv\").text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "the file all_201811-201812_Afghanistan.csv exists\n",
      "1\n",
      "the file all_201811-201812_Albania.csv exists\n",
      "2\n",
      "the file all_201811-201812_Algeria.csv exists\n",
      "3\n",
      "the file all_201811-201812_Andorra.csv exists\n",
      "4\n",
      "the file all_201811-201812_Angola.csv exists\n",
      "5\n",
      "the file all_201811-201812_Anguilla.csv exists\n",
      "6\n",
      "the file all_201811-201812_Antigua and Barbuda.csv exists\n",
      "7\n",
      "the file all_201811-201812_Argentina.csv exists\n",
      "8\n",
      "the file all_201811-201812_Armenia.csv exists\n",
      "9\n",
      "the file all_201811-201812_Aruba.csv exists\n",
      "10\n",
      "the file all_201811-201812_Australia.csv exists\n",
      "11\n",
      "the file all_201811-201812_Austria.csv exists\n",
      "12\n",
      "the file all_201811-201812_Azerbaijan.csv exists\n",
      "13\n",
      "the file all_201811-201812_Bahamas.csv exists\n",
      "14\n",
      "the file all_201811-201812_Bahrain.csv exists\n",
      "15\n",
      "the file all_201811-201812_Bangladesh.csv exists\n",
      "16\n",
      "the file all_201811-201812_Barbados.csv exists\n",
      "17\n",
      "the file all_201811-201812_Belarus.csv exists\n",
      "18\n",
      "the file all_201811-201812_Belgium.csv exists\n",
      "19\n",
      "the file all_201811-201812_Belgium-Luxembourg.csv exists\n",
      "20\n",
      "the file all_201811-201812_Belize.csv exists\n",
      "21\n",
      "the file all_201811-201812_Benin.csv exists\n",
      "22\n",
      "the file all_201811-201812_Bermuda.csv exists\n",
      "23\n",
      "the file all_201811-201812_Bhutan.csv exists\n",
      "24\n",
      "the file all_201811-201812_Bolivia (Plurinational State of).csv exists\n",
      "25\n",
      "the file all_201811-201812_Bonaire.csv exists\n",
      "26\n",
      "the file all_201811-201812_Bosnia Herzegovina.csv exists\n",
      "27\n",
      "the file all_201811-201812_Botswana.csv exists\n",
      "28\n",
      "the file all_201811-201812_Br. Virgin Isds.csv exists\n",
      "29\n",
      "the file all_201811-201812_Brazil.csv exists\n",
      "30\n",
      "the file all_201811-201812_Brunei Darussalam.csv exists\n",
      "31\n",
      "the file all_201811-201812_Bulgaria.csv exists\n",
      "32\n",
      "the file all_201811-201812_Burkina Faso.csv exists\n",
      "33\n",
      "the file all_201811-201812_Burundi.csv exists\n",
      "34\n",
      "the file all_201811-201812_Cabo Verde.csv exists\n",
      "35\n",
      "the file all_201811-201812_Cambodia.csv exists\n",
      "36\n",
      "the file all_201811-201812_Cameroon.csv exists\n",
      "37\n",
      "the file all_201811-201812_Canada.csv exists\n",
      "38\n",
      "the file all_201811-201812_Cayman Isds.csv exists\n",
      "39\n",
      "the file all_201811-201812_Central African Rep..csv exists\n",
      "40\n",
      "the file all_201811-201812_Chad.csv exists\n",
      "41\n",
      "the file all_201811-201812_Chile.csv exists\n",
      "42\n",
      "the file all_201811-201812_China.csv exists\n",
      "43\n",
      "the file all_201811-201812_China, Hong Kong SAR.csv exists\n",
      "44\n",
      "the file all_201811-201812_China, Macao SAR.csv exists\n",
      "45\n",
      "the file all_201811-201812_Colombia.csv exists\n",
      "46\n",
      "the file all_201811-201812_Comoros.csv exists\n",
      "47\n",
      "the file all_201811-201812_Congo.csv exists\n",
      "48\n",
      "the file all_201811-201812_Cook Isds.csv exists\n",
      "49\n",
      "the file all_201811-201812_Costa Rica.csv exists\n",
      "50\n",
      "the file all_201811-201812_Cote d'Ivoire.csv exists\n",
      "51\n",
      "the file all_201811-201812_Croatia.csv exists\n",
      "52\n",
      "the file all_201811-201812_Cuba.csv exists\n",
      "53\n",
      "the file all_201811-201812_Curacao.csv exists\n",
      "54\n",
      "the file all_201811-201812_Cyprus.csv exists\n",
      "55\n",
      "the file all_201811-201812_Czechia.csv exists\n",
      "56\n",
      "the file all_201811-201812_Czechoslovakia.csv exists\n",
      "57\n",
      "the file all_201811-201812_Dem. People's Rep. of Korea.csv exists\n",
      "58\n",
      "the file all_201811-201812_Dem. Rep. of the Congo.csv exists\n",
      "59\n",
      "the file all_201811-201812_Denmark.csv exists\n",
      "60\n",
      "the file all_201811-201812_Djibouti.csv exists\n",
      "61\n",
      "the file all_201811-201812_Dominica.csv exists\n",
      "62\n",
      "the file all_201811-201812_Dominican Rep..csv exists\n",
      "63\n",
      "the file all_201811-201812_East and West Pakistan.csv exists\n",
      "64\n",
      "the file all_201811-201812_Ecuador.csv exists\n",
      "65\n",
      "the file all_201811-201812_Egypt.csv exists\n",
      "66\n",
      "the file all_201811-201812_El Salvador.csv exists\n",
      "67\n",
      "the file all_201811-201812_Equatorial Guinea.csv exists\n",
      "68\n",
      "the file all_201811-201812_Eritrea.csv exists\n",
      "69\n",
      "the file all_201811-201812_Estonia.csv exists\n",
      "70\n",
      "the file all_201811-201812_Ethiopia.csv exists\n",
      "71\n",
      "the file all_201811-201812_EU-28.csv exists\n",
      "72\n",
      "the file all_201811-201812_Faeroe Isds.csv exists\n",
      "73\n",
      "the file all_201811-201812_Falkland Isds (Malvinas).csv exists\n",
      "74\n",
      "the file all_201811-201812_Fiji.csv exists\n",
      "75\n",
      "the file all_201811-201812_Finland.csv exists\n",
      "76\n",
      "the file all_201811-201812_France.csv exists\n",
      "77\n",
      "the file all_201811-201812_French Guiana.csv exists\n",
      "78\n",
      "the file all_201811-201812_French Polynesia.csv exists\n",
      "79\n",
      "the file all_201811-201812_FS Micronesia.csv exists\n",
      "80\n",
      "the file all_201811-201812_Gabon.csv exists\n",
      "81\n",
      "the file all_201811-201812_Gambia.csv exists\n",
      "82\n",
      "the file all_201811-201812_Georgia.csv exists\n",
      "83\n",
      "the file all_201811-201812_Germany.csv exists\n",
      "84\n",
      "the file all_201811-201812_Ghana.csv exists\n",
      "85\n",
      "the file all_201811-201812_Gibraltar.csv exists\n",
      "86\n",
      "the file all_201811-201812_Greece.csv exists\n",
      "87\n",
      "the file all_201811-201812_Greenland.csv exists\n",
      "88\n",
      "the file all_201811-201812_Grenada.csv exists\n",
      "89\n",
      "the file all_201811-201812_Guadeloupe.csv exists\n",
      "90\n",
      "the file all_201811-201812_Guatemala.csv exists\n",
      "91\n",
      "the file all_201811-201812_Guinea.csv exists\n",
      "92\n",
      "the file all_201811-201812_Guinea-Bissau.csv exists\n",
      "93\n",
      "the file all_201811-201812_Guyana.csv exists\n",
      "94\n",
      "the file all_201811-201812_Haiti.csv exists\n",
      "95\n",
      "the file all_201811-201812_Holy See (Vatican City State).csv exists\n",
      "96\n",
      "the file all_201811-201812_Honduras.csv exists\n",
      "97\n",
      "the file all_201811-201812_Hungary.csv exists\n",
      "98\n",
      "the file all_201811-201812_Iceland.csv exists\n",
      "99\n",
      "the file all_201811-201812_India.csv exists\n",
      "100\n",
      "the file all_201811-201812_India, excl. Sikkim.csv exists\n",
      "101\n",
      "the file all_201811-201812_Indonesia.csv exists\n",
      "102\n",
      "the file all_201811-201812_Iran.csv exists\n",
      "103\n",
      "the file all_201811-201812_Iraq.csv exists\n",
      "104\n",
      "the file all_201811-201812_Ireland.csv exists\n",
      "105\n",
      "the file all_201811-201812_Israel.csv exists\n",
      "106\n",
      "the file all_201811-201812_Italy.csv exists\n",
      "107\n",
      "the file all_201811-201812_Jamaica.csv exists\n",
      "108\n",
      "the file all_201811-201812_Japan.csv exists\n",
      "109\n",
      "the file all_201811-201812_Jordan.csv exists\n",
      "110\n",
      "the file all_201811-201812_Kazakhstan.csv exists\n",
      "111\n",
      "the file all_201811-201812_Kenya.csv exists\n",
      "112\n",
      "the file all_201811-201812_Kiribati.csv exists\n",
      "113\n",
      "the file all_201811-201812_Kuwait.csv exists\n",
      "114\n",
      "the file all_201811-201812_Kyrgyzstan.csv exists\n",
      "115\n",
      "the file all_201811-201812_Lao People's Dem. Rep..csv exists\n",
      "116\n",
      "the file all_201811-201812_Latvia.csv exists\n",
      "117\n",
      "the file all_201811-201812_Lebanon.csv exists\n",
      "118\n",
      "the file all_201811-201812_Lesotho.csv exists\n",
      "119\n",
      "the file all_201811-201812_Liberia.csv exists\n",
      "120\n",
      "the file all_201811-201812_Libya.csv exists\n",
      "121\n",
      "the file all_201811-201812_Lithuania.csv exists\n",
      "122\n",
      "the file all_201811-201812_Luxembourg.csv exists\n",
      "123\n",
      "the file all_201811-201812_Madagascar.csv exists\n",
      "124\n",
      "the file all_201811-201812_Malawi.csv exists\n",
      "125\n",
      "the file all_201811-201812_Malaysia.csv exists\n",
      "126\n",
      "the file all_201811-201812_Maldives.csv exists\n",
      "127\n",
      "the file all_201811-201812_Mali.csv exists\n",
      "128\n",
      "the file all_201811-201812_Malta.csv exists\n",
      "129\n",
      "the file all_201811-201812_Marshall Isds.csv exists\n",
      "130\n",
      "the file all_201811-201812_Martinique.csv exists\n",
      "131\n",
      "the file all_201811-201812_Mauritania.csv exists\n",
      "132\n",
      "the file all_201811-201812_Mauritius.csv exists\n",
      "133\n",
      "the file all_201811-201812_Mayotte.csv exists\n",
      "134\n",
      "the file all_201811-201812_Mexico.csv exists\n",
      "135\n",
      "the file all_201811-201812_Mongolia.csv exists\n",
      "136\n",
      "the file all_201811-201812_Montenegro.csv exists\n",
      "137\n",
      "the file all_201811-201812_Montserrat.csv exists\n",
      "138\n",
      "the file all_201811-201812_Morocco.csv exists\n",
      "139\n",
      "the file all_201811-201812_Mozambique.csv exists\n",
      "140\n",
      "the file all_201811-201812_Myanmar.csv exists\n",
      "141\n",
      "the file all_201811-201812_N. Mariana Isds.csv exists\n",
      "142\n",
      "the file all_201811-201812_Namibia.csv exists\n",
      "143\n",
      "the file all_201811-201812_Nepal.csv exists\n",
      "144\n",
      "the file all_201811-201812_Neth. Antilles.csv exists\n",
      "145\n",
      "the file all_201811-201812_Neth. Antilles and Aruba.csv exists\n",
      "146\n",
      "the file all_201811-201812_Netherlands.csv exists\n",
      "147\n",
      "the file all_201811-201812_New Caledonia.csv exists\n",
      "148\n",
      "the file all_201811-201812_New Zealand.csv exists\n",
      "149\n",
      "the file all_201811-201812_Nicaragua.csv exists\n",
      "150\n",
      "the file all_201811-201812_Niger.csv exists\n",
      "151\n",
      "the file all_201811-201812_Nigeria.csv exists\n",
      "152\n",
      "the file all_201811-201812_Norway.csv exists\n",
      "153\n",
      "the file all_201811-201812_Oman.csv exists\n",
      "154\n",
      "the file all_201811-201812_Other Asia, nes.csv exists\n",
      "155\n",
      "the file all_201811-201812_Pakistan.csv exists\n",
      "156\n",
      "the file all_201811-201812_Palau.csv exists\n",
      "157\n",
      "the file all_201811-201812_Panama.csv exists\n",
      "158\n",
      "the file all_201811-201812_Papua New Guinea.csv exists\n",
      "159\n",
      "the file all_201811-201812_Paraguay.csv exists\n",
      "160\n",
      "the file all_201811-201812_Peninsula Malaysia.csv exists\n",
      "161\n",
      "the file all_201811-201812_Peru.csv exists\n",
      "162\n",
      "the file all_201811-201812_Philippines.csv exists\n",
      "163\n",
      "the file all_201811-201812_Poland.csv exists\n",
      "164\n",
      "the file all_201811-201812_Portugal.csv exists\n",
      "165\n",
      "the file all_201811-201812_Qatar.csv exists\n",
      "166\n",
      "the file all_201811-201812_Rep. of Korea.csv exists\n",
      "167\n",
      "the file all_201811-201812_Rep. of Moldova.csv exists\n",
      "168\n",
      "the file all_201811-201812_Reunion.csv exists\n",
      "169\n",
      "the file all_201811-201812_Romania.csv exists\n",
      "170\n",
      "the file all_201811-201812_Russian Federation.csv exists\n",
      "171\n",
      "the file all_201811-201812_Rwanda.csv exists\n",
      "172\n",
      "the file all_201811-201812_Ryukyu Isd.csv exists\n",
      "173\n",
      "the file all_201811-201812_Sabah.csv exists\n",
      "174\n",
      "the file all_201811-201812_Saint Helena.csv exists\n",
      "175\n",
      "the file all_201811-201812_Saint Kitts and Nevis.csv exists\n",
      "176\n",
      "the file all_201811-201812_Saint Kitts, Nevis and Anguilla.csv exists\n",
      "177\n",
      "the file all_201811-201812_Saint Lucia.csv exists\n",
      "178\n",
      "the file all_201811-201812_Saint Maarten.csv exists\n",
      "179\n",
      "the file all_201811-201812_Saint Pierre and Miquelon.csv exists\n",
      "180\n",
      "the file all_201811-201812_Saint Vincent and the Grenadines.csv exists\n",
      "181\n",
      "the file all_201811-201812_Samoa.csv exists\n",
      "182\n",
      "the file all_201811-201812_San Marino.csv exists\n",
      "183\n",
      "the file all_201811-201812_Sao Tome and Principe.csv exists\n",
      "184\n",
      "the file all_201811-201812_Sarawak.csv exists\n",
      "185\n",
      "the file all_201811-201812_Saudi Arabia.csv exists\n",
      "186\n",
      "the file all_201811-201812_Senegal.csv exists\n",
      "187\n",
      "the file all_201811-201812_Serbia.csv exists\n",
      "188\n",
      "the file all_201811-201812_Serbia and Montenegro.csv exists\n",
      "189\n",
      "the file all_201811-201812_Seychelles.csv exists\n",
      "190\n",
      "the file all_201811-201812_Sierra Leone.csv exists\n",
      "191\n",
      "the file all_201811-201812_Singapore.csv exists\n",
      "192\n",
      "the file all_201811-201812_Slovakia.csv exists\n",
      "193\n",
      "the file all_201811-201812_Slovenia.csv exists\n",
      "194\n",
      "the file all_201811-201812_So. African Customs Union.csv exists\n",
      "195\n",
      "the file all_201811-201812_Solomon Isds.csv exists\n",
      "196\n",
      "the file all_201811-201812_Somalia.csv exists\n",
      "197\n",
      "the file all_201811-201812_South Africa.csv exists\n",
      "198\n",
      "the file all_201811-201812_South Sudan.csv exists\n",
      "199\n",
      "the file all_201811-201812_Spain.csv exists\n",
      "200\n",
      "the file all_201811-201812_Sri Lanka.csv exists\n",
      "201\n",
      "the file all_201811-201812_State of Palestine.csv exists\n",
      "202\n",
      "the file all_201811-201812_Sudan.csv exists\n",
      "203\n",
      "the file all_201811-201812_Suriname.csv exists\n",
      "204\n",
      "the file all_201811-201812_Swaziland.csv exists\n",
      "205\n",
      "the file all_201811-201812_Sweden.csv exists\n",
      "206\n",
      "the file all_201811-201812_Switzerland.csv exists\n",
      "207\n",
      "the file all_201811-201812_Syria.csv exists\n",
      "208\n",
      "the file all_201811-201812_Tajikistan.csv exists\n",
      "209\n",
      "the file all_201811-201812_TFYR of Macedonia.csv exists\n",
      "210\n",
      "the file all_201811-201812_Thailand.csv exists\n",
      "211\n",
      "the file all_201811-201812_Timor-Leste.csv exists\n",
      "212\n",
      "the file all_201811-201812_Togo.csv exists\n",
      "213\n",
      "the file all_201811-201812_Tokelau.csv exists\n",
      "214\n",
      "the file all_201811-201812_Tonga.csv exists\n",
      "215\n",
      "the file all_201811-201812_Trinidad and Tobago.csv exists\n",
      "216\n",
      "the file all_201811-201812_Tunisia.csv exists\n",
      "217\n",
      "the file all_201811-201812_Turkey.csv exists\n",
      "218\n",
      "the file all_201811-201812_Turkmenistan.csv exists\n",
      "219\n",
      "the file all_201811-201812_Turks and Caicos Isds.csv exists\n",
      "220\n",
      "the file all_201811-201812_Tuvalu.csv exists\n",
      "221\n",
      "the file all_201811-201812_Uganda.csv exists\n",
      "222\n",
      "the file all_201811-201812_Ukraine.csv exists\n",
      "223\n",
      "the file all_201811-201812_United Arab Emirates.csv exists\n",
      "224\n",
      "the file all_201811-201812_United Kingdom.csv exists\n",
      "225\n",
      "the file all_201811-201812_United Rep. of Tanzania.csv exists\n",
      "226\n",
      "the file all_201811-201812_Uruguay.csv exists\n",
      "227\n",
      "the file all_201811-201812_US Virgin Isds.csv exists\n",
      "228\n",
      "the file all_201811-201812_USA.csv exists\n",
      "229\n",
      "the file all_201811-201812_Uzbekistan.csv exists\n",
      "230\n",
      "the file all_201811-201812_Vanuatu.csv exists\n",
      "231\n",
      "the file all_201811-201812_Venezuela.csv exists\n",
      "232\n",
      "the file all_201811-201812_Viet Nam.csv exists\n",
      "233\n",
      "the file all_201811-201812_Wallis and Futuna Isds.csv exists\n",
      "234\n",
      "the file all_201811-201812_Yemen.csv exists\n",
      "235\n",
      "the file all_201811-201812_Zambia.csv exists\n",
      "236\n",
      "the file all_201811-201812_Zimbabwe.csv exists\n",
      "237\n",
      "the file all_201806-201810_Afghanistan.csv exists\n",
      "238\n",
      "the file all_201806-201810_Albania.csv exists\n",
      "239\n",
      "the file all_201806-201810_Algeria.csv exists\n",
      "240\n",
      "the file all_201806-201810_Andorra.csv exists\n",
      "241\n",
      "the file all_201806-201810_Angola.csv exists\n",
      "242\n",
      "the file all_201806-201810_Anguilla.csv exists\n",
      "243\n",
      "the file all_201806-201810_Antigua and Barbuda.csv exists\n",
      "244\n",
      "the file all_201806-201810_Argentina.csv exists\n",
      "245\n",
      "the file all_201806-201810_Armenia.csv exists\n",
      "246\n",
      "the file all_201806-201810_Aruba.csv exists\n",
      "247\n",
      "the file all_201806-201810_Australia.csv exists\n",
      "248\n",
      "the file all_201806-201810_Austria.csv exists\n",
      "249\n",
      "the file all_201806-201810_Azerbaijan.csv exists\n",
      "250\n",
      "the file all_201806-201810_Bahamas.csv exists\n",
      "251\n",
      "the file all_201806-201810_Bahrain.csv exists\n",
      "252\n",
      "the file all_201806-201810_Bangladesh.csv exists\n",
      "253\n",
      "the file all_201806-201810_Barbados.csv exists\n",
      "254\n",
      "the file all_201806-201810_Belarus.csv exists\n",
      "255\n",
      "the file all_201806-201810_Belgium.csv exists\n",
      "256\n",
      "the file all_201806-201810_Belgium-Luxembourg.csv exists\n",
      "257\n",
      "the file all_201806-201810_Belize.csv exists\n",
      "258\n",
      "the file all_201806-201810_Benin.csv exists\n",
      "259\n",
      "the file all_201806-201810_Bermuda.csv exists\n",
      "260\n",
      "the file all_201806-201810_Bhutan.csv exists\n",
      "261\n",
      "the file all_201806-201810_Bolivia (Plurinational State of).csv exists\n",
      "262\n",
      "the file all_201806-201810_Bonaire.csv exists\n",
      "263\n",
      "the file all_201806-201810_Bosnia Herzegovina.csv exists\n",
      "264\n",
      "the file all_201806-201810_Botswana.csv exists\n",
      "265\n",
      "the file all_201806-201810_Br. Virgin Isds.csv exists\n",
      "266\n",
      "the file all_201806-201810_Brazil.csv exists\n",
      "267\n",
      "the file all_201806-201810_Brunei Darussalam.csv exists\n",
      "268\n",
      "the file all_201806-201810_Bulgaria.csv exists\n",
      "269\n",
      "the file all_201806-201810_Burkina Faso.csv exists\n",
      "270\n",
      "the file all_201806-201810_Burundi.csv exists\n",
      "271\n",
      "the file all_201806-201810_Cabo Verde.csv exists\n",
      "272\n",
      "the file all_201806-201810_Cambodia.csv exists\n",
      "273\n",
      "the file all_201806-201810_Cameroon.csv exists\n",
      "274\n",
      "the file all_201806-201810_Canada.csv exists\n",
      "275\n",
      "the file all_201806-201810_Cayman Isds.csv exists\n",
      "276\n",
      "the file all_201806-201810_Central African Rep..csv exists\n",
      "277\n",
      "the file all_201806-201810_Chad.csv exists\n",
      "278\n",
      "the file all_201806-201810_Chile.csv exists\n",
      "279\n",
      "the file all_201806-201810_China.csv exists\n",
      "280\n",
      "the file all_201806-201810_China, Hong Kong SAR.csv exists\n",
      "281\n",
      "the file all_201806-201810_China, Macao SAR.csv exists\n",
      "282\n",
      "the file all_201806-201810_Colombia.csv exists\n",
      "283\n",
      "the file all_201806-201810_Comoros.csv exists\n",
      "284\n",
      "the file all_201806-201810_Congo.csv exists\n",
      "285\n",
      "the file all_201806-201810_Cook Isds.csv exists\n",
      "286\n",
      "the file all_201806-201810_Costa Rica.csv exists\n",
      "287\n",
      "the file all_201806-201810_Cote d'Ivoire.csv exists\n",
      "288\n",
      "the file all_201806-201810_Croatia.csv exists\n",
      "289\n",
      "the file all_201806-201810_Cuba.csv exists\n",
      "290\n",
      "the file all_201806-201810_Curacao.csv exists\n",
      "291\n",
      "the file all_201806-201810_Cyprus.csv exists\n",
      "292\n",
      "the file all_201806-201810_Czechia.csv exists\n",
      "293\n",
      "the file all_201806-201810_Czechoslovakia.csv exists\n",
      "294\n",
      "the file all_201806-201810_Dem. People's Rep. of Korea.csv exists\n",
      "295\n",
      "the file all_201806-201810_Dem. Rep. of the Congo.csv exists\n",
      "296\n",
      "the file all_201806-201810_Denmark.csv exists\n",
      "297\n",
      "the file all_201806-201810_Djibouti.csv exists\n",
      "298\n",
      "the file all_201806-201810_Dominica.csv exists\n",
      "299\n",
      "the file all_201806-201810_Dominican Rep..csv exists\n",
      "300\n",
      "the file all_201806-201810_East and West Pakistan.csv exists\n",
      "301\n",
      "the file all_201806-201810_Ecuador.csv exists\n",
      "302\n",
      "the file all_201806-201810_Egypt.csv exists\n",
      "303\n",
      "the file all_201806-201810_El Salvador.csv exists\n",
      "304\n",
      "the file all_201806-201810_Equatorial Guinea.csv exists\n",
      "305\n",
      "the file all_201806-201810_Eritrea.csv exists\n",
      "306\n",
      "the file all_201806-201810_Estonia.csv exists\n",
      "307\n",
      "the file all_201806-201810_Ethiopia.csv exists\n",
      "308\n",
      "the file all_201806-201810_EU-28.csv exists\n",
      "309\n",
      "the file all_201806-201810_Faeroe Isds.csv exists\n",
      "310\n",
      "the file all_201806-201810_Falkland Isds (Malvinas).csv exists\n",
      "311\n",
      "the file all_201806-201810_Fiji.csv exists\n",
      "312\n",
      "the file all_201806-201810_Finland.csv exists\n",
      "313\n",
      "the file all_201806-201810_France.csv exists\n",
      "314\n",
      "the file all_201806-201810_French Guiana.csv exists\n",
      "315\n",
      "the file all_201806-201810_French Polynesia.csv exists\n",
      "316\n",
      "the file all_201806-201810_FS Micronesia.csv exists\n",
      "317\n",
      "the file all_201806-201810_Gabon.csv exists\n",
      "318\n",
      "the file all_201806-201810_Gambia.csv exists\n",
      "319\n",
      "the file all_201806-201810_Georgia.csv exists\n",
      "320\n",
      "the file all_201806-201810_Germany.csv exists\n",
      "321\n",
      "the file all_201806-201810_Ghana.csv exists\n",
      "322\n",
      "the file all_201806-201810_Gibraltar.csv exists\n",
      "323\n",
      "the file all_201806-201810_Greece.csv exists\n",
      "324\n",
      "the file all_201806-201810_Greenland.csv exists\n",
      "325\n",
      "the file all_201806-201810_Grenada.csv exists\n",
      "326\n",
      "the file all_201806-201810_Guadeloupe.csv exists\n",
      "327\n",
      "the file all_201806-201810_Guatemala.csv exists\n",
      "328\n",
      "the file all_201806-201810_Guinea.csv exists\n",
      "329\n",
      "the file all_201806-201810_Guinea-Bissau.csv exists\n",
      "330\n",
      "the file all_201806-201810_Guyana.csv exists\n",
      "331\n",
      "the file all_201806-201810_Haiti.csv exists\n",
      "332\n",
      "the file all_201806-201810_Holy See (Vatican City State).csv exists\n",
      "333\n",
      "the file all_201806-201810_Honduras.csv exists\n",
      "334\n",
      "the file all_201806-201810_Hungary.csv exists\n",
      "335\n",
      "the file all_201806-201810_Iceland.csv exists\n",
      "336\n",
      "the file all_201806-201810_India.csv exists\n",
      "337\n",
      "the file all_201806-201810_India, excl. Sikkim.csv exists\n",
      "338\n",
      "the file all_201806-201810_Indonesia.csv exists\n",
      "339\n",
      "the file all_201806-201810_Iran.csv exists\n",
      "340\n",
      "the file all_201806-201810_Iraq.csv exists\n",
      "341\n",
      "the file all_201806-201810_Ireland.csv exists\n",
      "342\n",
      "the file all_201806-201810_Israel.csv exists\n",
      "343\n",
      "the file all_201806-201810_Italy.csv exists\n",
      "344\n",
      "the file all_201806-201810_Jamaica.csv exists\n",
      "345\n",
      "the file all_201806-201810_Japan.csv exists\n",
      "346\n",
      "the file all_201806-201810_Jordan.csv exists\n",
      "347\n",
      "the file all_201806-201810_Kazakhstan.csv exists\n",
      "348\n",
      "the file all_201806-201810_Kenya.csv exists\n",
      "349\n",
      "the file all_201806-201810_Kiribati.csv exists\n",
      "350\n",
      "the file all_201806-201810_Kuwait.csv exists\n",
      "351\n",
      "the file all_201806-201810_Kyrgyzstan.csv exists\n",
      "352\n",
      "the file all_201806-201810_Lao People's Dem. Rep..csv exists\n",
      "353\n",
      "the file all_201806-201810_Latvia.csv exists\n",
      "354\n",
      "the file all_201806-201810_Lebanon.csv exists\n",
      "355\n",
      "the file all_201806-201810_Lesotho.csv exists\n",
      "356\n",
      "the file all_201806-201810_Liberia.csv exists\n",
      "357\n",
      "the file all_201806-201810_Libya.csv exists\n",
      "358\n",
      "the file all_201806-201810_Lithuania.csv exists\n",
      "359\n",
      "the file all_201806-201810_Luxembourg.csv exists\n",
      "360\n",
      "the file all_201806-201810_Madagascar.csv exists\n",
      "361\n",
      "the file all_201806-201810_Malawi.csv exists\n",
      "362\n",
      "the file all_201806-201810_Malaysia.csv exists\n",
      "363\n",
      "the file all_201806-201810_Maldives.csv exists\n",
      "364\n",
      "the file all_201806-201810_Mali.csv exists\n",
      "365\n",
      "the file all_201806-201810_Malta.csv exists\n",
      "366\n",
      "the file all_201806-201810_Marshall Isds.csv exists\n",
      "367\n",
      "the file all_201806-201810_Martinique.csv exists\n",
      "368\n",
      "the file all_201806-201810_Mauritania.csv exists\n",
      "369\n",
      "the file all_201806-201810_Mauritius.csv exists\n",
      "370\n",
      "the file all_201806-201810_Mayotte.csv exists\n",
      "371\n",
      "the file all_201806-201810_Mexico.csv exists\n",
      "372\n",
      "the file all_201806-201810_Mongolia.csv exists\n",
      "373\n",
      "the file all_201806-201810_Montenegro.csv exists\n",
      "374\n",
      "the file all_201806-201810_Montserrat.csv exists\n",
      "375\n",
      "the file all_201806-201810_Morocco.csv exists\n",
      "376\n",
      "the file all_201806-201810_Mozambique.csv exists\n",
      "377\n",
      "the file all_201806-201810_Myanmar.csv exists\n",
      "378\n",
      "the file all_201806-201810_N. Mariana Isds.csv exists\n",
      "379\n",
      "the file all_201806-201810_Namibia.csv exists\n",
      "380\n",
      "the file all_201806-201810_Nepal.csv exists\n",
      "381\n",
      "the file all_201806-201810_Neth. Antilles.csv exists\n",
      "382\n",
      "the file all_201806-201810_Neth. Antilles and Aruba.csv exists\n",
      "383\n",
      "the file all_201806-201810_Netherlands.csv exists\n",
      "384\n",
      "the file all_201806-201810_New Caledonia.csv exists\n",
      "385\n",
      "the file all_201806-201810_New Zealand.csv exists\n",
      "386\n",
      "the file all_201806-201810_Nicaragua.csv exists\n",
      "387\n",
      "the file all_201806-201810_Niger.csv exists\n",
      "388\n",
      "the file all_201806-201810_Nigeria.csv exists\n",
      "389\n",
      "the file all_201806-201810_Norway.csv exists\n",
      "390\n",
      "the file all_201806-201810_Oman.csv exists\n",
      "391\n",
      "the file all_201806-201810_Other Asia, nes.csv exists\n",
      "392\n",
      "the file all_201806-201810_Pakistan.csv exists\n",
      "393\n",
      "the file all_201806-201810_Palau.csv exists\n",
      "394\n",
      "the file all_201806-201810_Panama.csv exists\n",
      "395\n",
      "the file all_201806-201810_Papua New Guinea.csv exists\n",
      "396\n",
      "the file all_201806-201810_Paraguay.csv exists\n",
      "397\n",
      "the file all_201806-201810_Peninsula Malaysia.csv exists\n",
      "398\n",
      "the file all_201806-201810_Peru.csv exists\n",
      "399\n",
      "the file all_201806-201810_Philippines.csv exists\n",
      "400\n",
      "the file all_201806-201810_Poland.csv exists\n",
      "401\n",
      "the file all_201806-201810_Portugal.csv exists\n",
      "402\n",
      "the file all_201806-201810_Qatar.csv exists\n",
      "403\n",
      "the file all_201806-201810_Rep. of Korea.csv exists\n",
      "404\n",
      "the file all_201806-201810_Rep. of Moldova.csv exists\n",
      "405\n",
      "the file all_201806-201810_Reunion.csv exists\n",
      "406\n",
      "the file all_201806-201810_Romania.csv exists\n",
      "407\n",
      "the file all_201806-201810_Russian Federation.csv exists\n",
      "408\n",
      "the file all_201806-201810_Rwanda.csv exists\n",
      "409\n",
      "the file all_201806-201810_Ryukyu Isd.csv exists\n",
      "410\n",
      "the file all_201806-201810_Sabah.csv exists\n",
      "411\n",
      "the file all_201806-201810_Saint Helena.csv exists\n",
      "412\n",
      "the file all_201806-201810_Saint Kitts and Nevis.csv exists\n",
      "413\n",
      "the file all_201806-201810_Saint Kitts, Nevis and Anguilla.csv exists\n",
      "414\n",
      "the file all_201806-201810_Saint Lucia.csv exists\n",
      "415\n",
      "the file all_201806-201810_Saint Maarten.csv exists\n",
      "416\n",
      "the file all_201806-201810_Saint Pierre and Miquelon.csv exists\n",
      "417\n",
      "the file all_201806-201810_Saint Vincent and the Grenadines.csv exists\n",
      "418\n",
      "the file all_201806-201810_Samoa.csv exists\n",
      "419\n",
      "the file all_201806-201810_San Marino.csv exists\n",
      "420\n",
      "the file all_201806-201810_Sao Tome and Principe.csv exists\n",
      "421\n",
      "the file all_201806-201810_Sarawak.csv exists\n",
      "422\n",
      "the file all_201806-201810_Saudi Arabia.csv exists\n",
      "423\n",
      "the file all_201806-201810_Senegal.csv exists\n",
      "424\n",
      "the file all_201806-201810_Serbia.csv exists\n",
      "425\n",
      "the file all_201806-201810_Serbia and Montenegro.csv exists\n",
      "426\n",
      "the file all_201806-201810_Seychelles.csv exists\n",
      "427\n",
      "the file all_201806-201810_Sierra Leone.csv exists\n",
      "428\n",
      "the file all_201806-201810_Singapore.csv exists\n",
      "429\n",
      "the file all_201806-201810_Slovakia.csv exists\n",
      "430\n",
      "the file all_201806-201810_Slovenia.csv exists\n",
      "431\n",
      "the file all_201806-201810_So. African Customs Union.csv exists\n",
      "432\n",
      "the file all_201806-201810_Solomon Isds.csv exists\n",
      "433\n",
      "the file all_201806-201810_Somalia.csv exists\n",
      "434\n",
      "the file all_201806-201810_South Africa.csv exists\n",
      "435\n",
      "the file all_201806-201810_South Sudan.csv exists\n",
      "436\n",
      "the file all_201806-201810_Spain.csv exists\n",
      "437\n",
      "the file all_201806-201810_Sri Lanka.csv exists\n",
      "438\n",
      "the file all_201806-201810_State of Palestine.csv exists\n",
      "439\n",
      "the file all_201806-201810_Sudan.csv exists\n",
      "440\n",
      "the file all_201806-201810_Suriname.csv exists\n",
      "441\n",
      "the file all_201806-201810_Swaziland.csv exists\n",
      "442\n",
      "the file all_201806-201810_Sweden.csv exists\n",
      "443\n",
      "the file all_201806-201810_Switzerland.csv exists\n",
      "444\n",
      "the file all_201806-201810_Syria.csv exists\n",
      "445\n",
      "the file all_201806-201810_Tajikistan.csv exists\n",
      "446\n",
      "the file all_201806-201810_TFYR of Macedonia.csv exists\n",
      "447\n",
      "the file all_201806-201810_Thailand.csv exists\n",
      "448\n",
      "the file all_201806-201810_Timor-Leste.csv exists\n",
      "449\n",
      "the file all_201806-201810_Togo.csv exists\n",
      "450\n",
      "the file all_201806-201810_Tokelau.csv exists\n",
      "451\n",
      "the file all_201806-201810_Tonga.csv exists\n",
      "452\n",
      "the file all_201806-201810_Trinidad and Tobago.csv exists\n",
      "453\n",
      "the file all_201806-201810_Tunisia.csv exists\n",
      "454\n",
      "the file all_201806-201810_Turkey.csv exists\n",
      "455\n",
      "the file all_201806-201810_Turkmenistan.csv exists\n",
      "456\n",
      "the file all_201806-201810_Turks and Caicos Isds.csv exists\n",
      "457\n",
      "the file all_201806-201810_Tuvalu.csv exists\n",
      "458\n",
      "the file all_201806-201810_Uganda.csv exists\n",
      "459\n",
      "the file all_201806-201810_Ukraine.csv exists\n",
      "460\n",
      "the file all_201806-201810_United Arab Emirates.csv exists\n",
      "461\n",
      "the file all_201806-201810_United Kingdom.csv exists\n",
      "462\n",
      "the file all_201806-201810_United Rep. of Tanzania.csv exists\n",
      "463\n",
      "the file all_201806-201810_Uruguay.csv exists\n",
      "464\n",
      "the file all_201806-201810_US Virgin Isds.csv exists\n",
      "465\n",
      "the file all_201806-201810_USA.csv exists\n",
      "466\n",
      "the file all_201806-201810_Uzbekistan.csv exists\n",
      "467\n",
      "the file all_201806-201810_Vanuatu.csv exists\n",
      "468\n",
      "the file all_201806-201810_Venezuela.csv exists\n",
      "469\n",
      "the file all_201806-201810_Viet Nam.csv exists\n",
      "470\n",
      "the file all_201806-201810_Wallis and Futuna Isds.csv exists\n",
      "471\n",
      "the file all_201806-201810_Yemen.csv exists\n",
      "472\n",
      "the file all_201806-201810_Zambia.csv exists\n",
      "473\n",
      "the file all_201806-201810_Zimbabwe.csv exists\n",
      "474\n",
      "the file all_201801-201805_Afghanistan.csv exists\n",
      "475\n",
      "the file all_201801-201805_Albania.csv exists\n",
      "476\n",
      "the file all_201801-201805_Algeria.csv exists\n",
      "477\n",
      "the file all_201801-201805_Andorra.csv exists\n",
      "478\n",
      "the file all_201801-201805_Angola.csv exists\n",
      "479\n",
      "the file all_201801-201805_Anguilla.csv exists\n",
      "480\n",
      "the file all_201801-201805_Antigua and Barbuda.csv exists\n",
      "481\n",
      "the file all_201801-201805_Argentina.csv exists\n",
      "482\n",
      "the file all_201801-201805_Armenia.csv exists\n",
      "483\n",
      "the file all_201801-201805_Aruba.csv exists\n",
      "484\n",
      "the file all_201801-201805_Australia.csv exists\n",
      "485\n",
      "the file all_201801-201805_Austria.csv exists\n",
      "486\n",
      "the file all_201801-201805_Azerbaijan.csv exists\n",
      "487\n",
      "the file all_201801-201805_Bahamas.csv exists\n",
      "488\n",
      "the file all_201801-201805_Bahrain.csv exists\n",
      "489\n",
      "the file all_201801-201805_Bangladesh.csv exists\n",
      "490\n",
      "the file all_201801-201805_Barbados.csv exists\n",
      "491\n",
      "the file all_201801-201805_Belarus.csv exists\n",
      "492\n",
      "the file all_201801-201805_Belgium.csv exists\n",
      "493\n",
      "the file all_201801-201805_Belgium-Luxembourg.csv exists\n",
      "494\n",
      "the file all_201801-201805_Belize.csv exists\n",
      "495\n",
      "the file all_201801-201805_Benin.csv exists\n",
      "496\n",
      "the file all_201801-201805_Bermuda.csv exists\n",
      "497\n",
      "the file all_201801-201805_Bhutan.csv exists\n",
      "498\n",
      "the file all_201801-201805_Bolivia (Plurinational State of).csv exists\n",
      "499\n",
      "the file all_201801-201805_Bonaire.csv exists\n",
      "500\n",
      "the file all_201801-201805_Bosnia Herzegovina.csv exists\n",
      "501\n",
      "the file all_201801-201805_Botswana.csv exists\n",
      "502\n",
      "the file all_201801-201805_Br. Virgin Isds.csv exists\n",
      "503\n",
      "the file all_201801-201805_Brazil.csv exists\n",
      "504\n",
      "the file all_201801-201805_Brunei Darussalam.csv exists\n",
      "505\n",
      "the file all_201801-201805_Bulgaria.csv exists\n",
      "506\n",
      "the file all_201801-201805_Burkina Faso.csv exists\n",
      "507\n",
      "the file all_201801-201805_Burundi.csv exists\n",
      "508\n",
      "the file all_201801-201805_Cabo Verde.csv exists\n",
      "509\n",
      "the file all_201801-201805_Cambodia.csv exists\n",
      "510\n",
      "the file all_201801-201805_Cameroon.csv exists\n",
      "511\n",
      "the file all_201801-201805_Canada.csv exists\n",
      "512\n",
      "the file all_201801-201805_Cayman Isds.csv exists\n",
      "513\n",
      "the file all_201801-201805_Central African Rep..csv exists\n",
      "514\n",
      "the file all_201801-201805_Chad.csv exists\n",
      "515\n",
      "the file all_201801-201805_Chile.csv exists\n",
      "516\n",
      "the file all_201801-201805_China.csv exists\n",
      "517\n",
      "the file all_201801-201805_China, Hong Kong SAR.csv exists\n",
      "518\n",
      "the file all_201801-201805_China, Macao SAR.csv exists\n",
      "519\n",
      "the file all_201801-201805_Colombia.csv exists\n",
      "520\n",
      "the file all_201801-201805_Comoros.csv exists\n",
      "521\n",
      "the file all_201801-201805_Congo.csv exists\n",
      "522\n",
      "the file all_201801-201805_Cook Isds.csv exists\n",
      "523\n",
      "the file all_201801-201805_Costa Rica.csv exists\n",
      "524\n",
      "the file all_201801-201805_Cote d'Ivoire.csv exists\n",
      "525\n",
      "the file all_201801-201805_Croatia.csv exists\n",
      "526\n",
      "the file all_201801-201805_Cuba.csv exists\n",
      "527\n",
      "the file all_201801-201805_Curacao.csv exists\n",
      "528\n",
      "the file all_201801-201805_Cyprus.csv exists\n",
      "529\n",
      "the file all_201801-201805_Czechia.csv exists\n",
      "530\n",
      "the file all_201801-201805_Czechoslovakia.csv exists\n",
      "531\n",
      "the file all_201801-201805_Dem. People's Rep. of Korea.csv exists\n",
      "532\n",
      "the file all_201801-201805_Dem. Rep. of the Congo.csv exists\n",
      "533\n",
      "the file all_201801-201805_Denmark.csv exists\n",
      "534\n",
      "the file all_201801-201805_Djibouti.csv exists\n",
      "535\n",
      "the file all_201801-201805_Dominica.csv exists\n",
      "536\n",
      "the file all_201801-201805_Dominican Rep..csv exists\n",
      "537\n",
      "the file all_201801-201805_East and West Pakistan.csv exists\n",
      "538\n",
      "the file all_201801-201805_Ecuador.csv exists\n",
      "539\n",
      "the file all_201801-201805_Egypt.csv exists\n",
      "540\n",
      "the file all_201801-201805_El Salvador.csv exists\n",
      "541\n",
      "the file all_201801-201805_Equatorial Guinea.csv exists\n",
      "542\n",
      "the file all_201801-201805_Eritrea.csv exists\n",
      "543\n",
      "the file all_201801-201805_Estonia.csv exists\n",
      "544\n",
      "the file all_201801-201805_Ethiopia.csv exists\n",
      "545\n",
      "the file all_201801-201805_EU-28.csv exists\n",
      "546\n",
      "the file all_201801-201805_Faeroe Isds.csv exists\n",
      "547\n",
      "the file all_201801-201805_Falkland Isds (Malvinas).csv exists\n",
      "548\n",
      "the file all_201801-201805_Fiji.csv exists\n",
      "549\n",
      "the file all_201801-201805_Finland.csv exists\n",
      "550\n",
      "the file all_201801-201805_France.csv exists\n",
      "551\n",
      "the file all_201801-201805_French Guiana.csv exists\n",
      "552\n",
      "the file all_201801-201805_French Polynesia.csv exists\n",
      "553\n",
      "the file all_201801-201805_FS Micronesia.csv exists\n",
      "554\n",
      "the file all_201801-201805_Gabon.csv exists\n",
      "555\n",
      "the file all_201801-201805_Gambia.csv exists\n",
      "556\n",
      "the file all_201801-201805_Georgia.csv exists\n",
      "557\n",
      "the file all_201801-201805_Germany.csv exists\n",
      "558\n",
      "the file all_201801-201805_Ghana.csv exists\n",
      "559\n",
      "the file all_201801-201805_Gibraltar.csv exists\n",
      "560\n",
      "the file all_201801-201805_Greece.csv exists\n",
      "561\n",
      "the file all_201801-201805_Greenland.csv exists\n",
      "562\n",
      "the file all_201801-201805_Grenada.csv exists\n",
      "563\n",
      "the file all_201801-201805_Guadeloupe.csv exists\n",
      "564\n",
      "the file all_201801-201805_Guatemala.csv exists\n",
      "565\n",
      "the file all_201801-201805_Guinea.csv exists\n",
      "566\n",
      "the file all_201801-201805_Guinea-Bissau.csv exists\n",
      "567\n",
      "the file all_201801-201805_Guyana.csv exists\n",
      "568\n",
      "the file all_201801-201805_Haiti.csv exists\n",
      "569\n",
      "the file all_201801-201805_Holy See (Vatican City State).csv exists\n",
      "570\n",
      "the file all_201801-201805_Honduras.csv exists\n",
      "571\n",
      "the file all_201801-201805_Hungary.csv exists\n",
      "572\n",
      "the file all_201801-201805_Iceland.csv exists\n",
      "573\n",
      "the file all_201801-201805_India.csv exists\n",
      "574\n",
      "the file all_201801-201805_India, excl. Sikkim.csv exists\n",
      "575\n",
      "the file all_201801-201805_Indonesia.csv exists\n",
      "576\n",
      "the file all_201801-201805_Iran.csv exists\n",
      "577\n",
      "the file all_201801-201805_Iraq.csv exists\n",
      "578\n",
      "the file all_201801-201805_Ireland.csv exists\n",
      "579\n",
      "the file all_201801-201805_Israel.csv exists\n",
      "580\n",
      "the file all_201801-201805_Italy.csv exists\n",
      "581\n",
      "the file all_201801-201805_Jamaica.csv exists\n",
      "582\n",
      "the file all_201801-201805_Japan.csv exists\n",
      "583\n",
      "the file all_201801-201805_Jordan.csv exists\n",
      "584\n",
      "the file all_201801-201805_Kazakhstan.csv exists\n",
      "585\n",
      "the file all_201801-201805_Kenya.csv exists\n",
      "586\n",
      "the file all_201801-201805_Kiribati.csv exists\n",
      "587\n",
      "the file all_201801-201805_Kuwait.csv exists\n",
      "588\n",
      "the file all_201801-201805_Kyrgyzstan.csv exists\n",
      "589\n",
      "the file all_201801-201805_Lao People's Dem. Rep..csv exists\n",
      "590\n",
      "the file all_201801-201805_Latvia.csv exists\n",
      "591\n",
      "the file all_201801-201805_Lebanon.csv exists\n",
      "592\n",
      "the file all_201801-201805_Lesotho.csv exists\n",
      "593\n",
      "the file all_201801-201805_Liberia.csv exists\n",
      "594\n",
      "the file all_201801-201805_Libya.csv exists\n",
      "595\n",
      "the file all_201801-201805_Lithuania.csv exists\n",
      "596\n",
      "the file all_201801-201805_Luxembourg.csv exists\n",
      "597\n",
      "the file all_201801-201805_Madagascar.csv exists\n",
      "598\n",
      "the file all_201801-201805_Malawi.csv exists\n",
      "599\n",
      "the file all_201801-201805_Malaysia.csv exists\n",
      "600\n",
      "the file all_201801-201805_Maldives.csv exists\n",
      "601\n",
      "the file all_201801-201805_Mali.csv exists\n",
      "602\n",
      "the file all_201801-201805_Malta.csv exists\n",
      "603\n",
      "the file all_201801-201805_Marshall Isds.csv exists\n",
      "604\n",
      "the file all_201801-201805_Martinique.csv exists\n",
      "605\n",
      "the file all_201801-201805_Mauritania.csv exists\n",
      "606\n",
      "the file all_201801-201805_Mauritius.csv exists\n",
      "607\n",
      "the file all_201801-201805_Mayotte.csv exists\n",
      "608\n",
      "the file all_201801-201805_Mexico.csv exists\n",
      "609\n",
      "the file all_201801-201805_Mongolia.csv exists\n",
      "610\n",
      "the file all_201801-201805_Montenegro.csv exists\n",
      "611\n",
      "the file all_201801-201805_Montserrat.csv exists\n",
      "612\n",
      "the file all_201801-201805_Morocco.csv exists\n",
      "613\n",
      "the file all_201801-201805_Mozambique.csv exists\n",
      "614\n",
      "the file all_201801-201805_Myanmar.csv exists\n",
      "615\n",
      "the file all_201801-201805_N. Mariana Isds.csv exists\n",
      "616\n",
      "the file all_201801-201805_Namibia.csv exists\n",
      "617\n",
      "the file all_201801-201805_Nepal.csv exists\n",
      "618\n",
      "the file all_201801-201805_Neth. Antilles.csv exists\n",
      "619\n",
      "the file all_201801-201805_Neth. Antilles and Aruba.csv exists\n",
      "620\n",
      "the file all_201801-201805_Netherlands.csv exists\n",
      "621\n",
      "the file all_201801-201805_New Caledonia.csv exists\n",
      "622\n",
      "the file all_201801-201805_New Zealand.csv exists\n",
      "623\n",
      "the file all_201801-201805_Nicaragua.csv exists\n",
      "624\n",
      "the file all_201801-201805_Niger.csv exists\n",
      "625\n",
      "the file all_201801-201805_Nigeria.csv exists\n",
      "626\n",
      "the file all_201801-201805_Norway.csv exists\n",
      "627\n",
      "the file all_201801-201805_Oman.csv exists\n",
      "628\n",
      "the file all_201801-201805_Other Asia, nes.csv exists\n",
      "629\n",
      "the file all_201801-201805_Pakistan.csv exists\n",
      "630\n",
      "the file all_201801-201805_Palau.csv exists\n",
      "631\n",
      "the file all_201801-201805_Panama.csv exists\n",
      "632\n",
      "the file all_201801-201805_Papua New Guinea.csv exists\n",
      "633\n",
      "the file all_201801-201805_Paraguay.csv exists\n",
      "634\n",
      "the file all_201801-201805_Peninsula Malaysia.csv exists\n",
      "635\n",
      "the file all_201801-201805_Peru.csv exists\n",
      "636\n",
      "the file all_201801-201805_Philippines.csv exists\n",
      "637\n",
      "the file all_201801-201805_Poland.csv exists\n",
      "638\n",
      "the file all_201801-201805_Portugal.csv exists\n",
      "639\n",
      "the file all_201801-201805_Qatar.csv exists\n",
      "640\n",
      "the file all_201801-201805_Rep. of Korea.csv exists\n",
      "641\n",
      "the file all_201801-201805_Rep. of Moldova.csv exists\n",
      "642\n",
      "the file all_201801-201805_Reunion.csv exists\n",
      "643\n",
      "the file all_201801-201805_Romania.csv exists\n",
      "644\n",
      "the file all_201801-201805_Russian Federation.csv exists\n",
      "645\n",
      "the file all_201801-201805_Rwanda.csv exists\n",
      "646\n",
      "the file all_201801-201805_Ryukyu Isd.csv exists\n",
      "647\n",
      "the file all_201801-201805_Sabah.csv exists\n",
      "648\n",
      "the file all_201801-201805_Saint Helena.csv exists\n",
      "649\n",
      "the file all_201801-201805_Saint Kitts and Nevis.csv exists\n",
      "650\n",
      "the file all_201801-201805_Saint Kitts, Nevis and Anguilla.csv exists\n",
      "651\n",
      "the file all_201801-201805_Saint Lucia.csv exists\n",
      "652\n",
      "the file all_201801-201805_Saint Maarten.csv exists\n",
      "653\n",
      "the file all_201801-201805_Saint Pierre and Miquelon.csv exists\n",
      "654\n",
      "the file all_201801-201805_Saint Vincent and the Grenadines.csv exists\n",
      "655\n",
      "the file all_201801-201805_Samoa.csv exists\n",
      "656\n",
      "the file all_201801-201805_San Marino.csv exists\n",
      "657\n",
      "the file all_201801-201805_Sao Tome and Principe.csv exists\n",
      "658\n",
      "the file all_201801-201805_Sarawak.csv exists\n",
      "659\n",
      "the file all_201801-201805_Saudi Arabia.csv exists\n",
      "660\n",
      "the file all_201801-201805_Senegal.csv exists\n",
      "661\n",
      "the file all_201801-201805_Serbia.csv exists\n",
      "662\n",
      "the file all_201801-201805_Serbia and Montenegro.csv exists\n",
      "663\n",
      "the file all_201801-201805_Seychelles.csv exists\n",
      "664\n",
      "the file all_201801-201805_Sierra Leone.csv exists\n",
      "665\n",
      "the file all_201801-201805_Singapore.csv exists\n",
      "666\n",
      "the file all_201801-201805_Slovakia.csv exists\n",
      "667\n",
      "the file all_201801-201805_Slovenia.csv exists\n",
      "668\n",
      "the file all_201801-201805_So. African Customs Union.csv exists\n",
      "669\n",
      "the file all_201801-201805_Solomon Isds.csv exists\n",
      "670\n",
      "the file all_201801-201805_Somalia.csv exists\n",
      "671\n",
      "the file all_201801-201805_South Africa.csv exists\n",
      "672\n",
      "the file all_201801-201805_South Sudan.csv exists\n",
      "673\n",
      "the file all_201801-201805_Spain.csv exists\n",
      "674\n",
      "the file all_201801-201805_Sri Lanka.csv exists\n",
      "675\n",
      "the file all_201801-201805_State of Palestine.csv exists\n",
      "676\n",
      "the file all_201801-201805_Sudan.csv exists\n",
      "677\n",
      "the file all_201801-201805_Suriname.csv exists\n",
      "678\n",
      "the file all_201801-201805_Swaziland.csv exists\n",
      "679\n",
      "the file all_201801-201805_Sweden.csv exists\n",
      "680\n",
      "the file all_201801-201805_Switzerland.csv exists\n",
      "681\n",
      "the file all_201801-201805_Syria.csv exists\n",
      "682\n",
      "the file all_201801-201805_Tajikistan.csv exists\n",
      "683\n",
      "the file all_201801-201805_TFYR of Macedonia.csv exists\n",
      "684\n",
      "the file all_201801-201805_Thailand.csv exists\n",
      "685\n",
      "the file all_201801-201805_Timor-Leste.csv exists\n",
      "686\n",
      "the file all_201801-201805_Togo.csv exists\n",
      "687\n",
      "the file all_201801-201805_Tokelau.csv exists\n",
      "688\n",
      "the file all_201801-201805_Tonga.csv exists\n",
      "689\n",
      "the file all_201801-201805_Trinidad and Tobago.csv exists\n",
      "690\n",
      "the file all_201801-201805_Tunisia.csv exists\n",
      "691\n",
      "the file all_201801-201805_Turkey.csv exists\n",
      "692\n",
      "the file all_201801-201805_Turkmenistan.csv exists\n",
      "693\n",
      "the file all_201801-201805_Turks and Caicos Isds.csv exists\n",
      "694\n",
      "the file all_201801-201805_Tuvalu.csv exists\n",
      "695\n",
      "the file all_201801-201805_Uganda.csv exists\n",
      "696\n",
      "the file all_201801-201805_Ukraine.csv exists\n",
      "697\n",
      "the file all_201801-201805_United Arab Emirates.csv exists\n",
      "698\n",
      "the file all_201801-201805_United Kingdom.csv exists\n",
      "699\n",
      "the file all_201801-201805_United Rep. of Tanzania.csv exists\n",
      "700\n",
      "the file all_201801-201805_Uruguay.csv exists\n",
      "701\n",
      "the file all_201801-201805_US Virgin Isds.csv exists\n",
      "702\n",
      "the file all_201801-201805_USA.csv exists\n",
      "703\n",
      "the file all_201801-201805_Uzbekistan.csv exists\n",
      "704\n",
      "the file all_201801-201805_Vanuatu.csv exists\n",
      "705\n",
      "the file all_201801-201805_Venezuela.csv exists\n",
      "706\n",
      "the file all_201801-201805_Viet Nam.csv exists\n",
      "707\n",
      "the file all_201801-201805_Wallis and Futuna Isds.csv exists\n",
      "708\n",
      "the file all_201801-201805_Yemen.csv exists\n",
      "709\n",
      "the file all_201801-201805_Zambia.csv exists\n",
      "710\n",
      "the file all_201801-201805_Zimbabwe.csv exists\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "r=0\n",
    "rph = 95\n",
    "wait_s = 60*60\n",
    "for part in partners:\n",
    "    for tf in trade_flows:\n",
    "        for p in periods:\n",
    "            for rep in reporters:\n",
    "                print(i)\n",
    "                file = '{}_{}_{}.csv'.format(tf,p,rep)\n",
    "                my_file = Path(file)\n",
    "                if not my_file.is_file():\n",
    "                    print('Requesting data for {}...'.format(file))\n",
    "                    try:\n",
    "                        reqs = download_trade_data(file, period=p, frequency='M', reporter=rep, \n",
    "                                                   partner=part, product='all', tradeflow=tf)\n",
    "                    except Exception as e: \n",
    "                        print(e)\n",
    "                        print(\"There was a problem downloading the data\")\n",
    "                        if \"Expecting\" in str(e):\n",
    "                            wakingup_at = datetime.datetime.strftime(datetime.datetime.today() + datetime.timedelta(seconds = wait_s) , '%d/%m/%Y:%H:%M')\n",
    "                            print(\"Sleeping for an hour, resuming at {}\".format(wakingup_at))\n",
    "                            sleep(wait_s)\n",
    "                        sleep(1)\n",
    "                    else:\n",
    "                        r += reqs if reqs > 0 else 1\n",
    "                        print(\"{} requests this session\".format(r))\n",
    "                        sleep(1)\n",
    "                else:\n",
    "                    print(\"the file {} exists\".format(file))\n",
    "                i += 1\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NIC: Sleeping for an hour, resuming at 06/12/2018:18:55\n",
    "Phone: Sleeping for an hour, resuming at 06/12/2018:18:16\n",
    "dongle: Sleeping for an hour, resuming at 06/12/2018:18:36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_flows = ['all']\n",
    "trade_flows.reverse()\n",
    "reporters = pd.read_csv(\"reporterAreas.csv\").text\n",
    "newrep = reporters#[x for x in list(reporters) if x not in notrade]\n",
    "periods = ['201401-201405','201406-201410','201411-201503','201504-201508','201509-201601','201602-201606',\n",
    "           '201607-201611','201612-201704','201705-201709','201710-201712']\n",
    "periods.reverse()\n",
    "partners_codes = pd.read_csv(\"partners.csv\")\n",
    "partners_mapping = pd.read_csv(\"partners_mapping.csv\")\n",
    "partners = [\"World\"]\n",
    "# for name in partners_codes.partner_name.values:\n",
    "#     try:\n",
    "#         partners.append(name)\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting data for World_all_201401_China.csv...\n",
      "https://comtrade.un.org/api/get?ps=201401&freq=M&r=156&p=0&cc=all&rg=all&px=HS&type=C&fmt=json&max=100000&head=M\n",
      "Error: empty dataset \n",
      " Message: None\n"
     ]
    }
   ],
   "source": [
    "wait_s = 60*60\n",
    "for p in periods:\n",
    "    for part in partners:\n",
    "        for tf in trade_flows:\n",
    "            for rep in newrep:\n",
    "                file = '{}_{}_{}_{}.csv'.format(part,tf,p,rep)\n",
    "                my_file = Path(file)\n",
    "                if not my_file.is_file():\n",
    "                    print('Requesting data for {}...'.format(file))\n",
    "                    try:\n",
    "                        reqs = download_trade_data(file, period=p, frequency='M', reporter=rep, \n",
    "                                                   partner=part, product='all', tradeflow=tf, verbose=True)\n",
    "                    except Exception as e: \n",
    "                        print(e)\n",
    "                        if \"Expecting\" in str(e):\n",
    "                            wakingup_at = datetime.datetime.strftime(datetime.datetime.today() + datetime.timedelta(seconds = wait_s) , '%d/%m/%Y:%H:%M')\n",
    "                            print(\"Sleeping for an hour, resuming at {}\".format(wakingup_at))\n",
    "                            sleep(wait_s)\n",
    "                        sleep(1)\n",
    "                    else:\n",
    "                        sleep(1)\n",
    "                else:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = os.path.join(\"C:\\\\\",\"Users\\sahabi\\notebooks\\data\")\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "       if file.endswith(\".csv\"):\n",
    "           print(file)\n",
    "           #  perform calculation\n",
    "#            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sahabi\\notebooks\\\\data'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object walk at 0x000001931D715620>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.walk(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'root' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-552c0ba71b10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mroot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'root' is not defined"
     ]
    }
   ],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "dfs = []\n",
    "for f in glob.glob(\"C:\\\\Users\\\\sahabi\\\\notebooks\\\\data\\\\\"+'*.csv'):\n",
    "    dfs.append(pd.read_csv(f)[['yr','NetWeight','TradeValue','aggrLevel','cmdCode','cmdDescE','period','rgDesc','rtTitle']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(688380, 9)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(dfs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'AltQuantity', 'CIFValue', 'FOBValue', 'GrossWeight',\n",
       "       'IsLeaf', 'NetWeight', 'TradeQuantity', 'TradeValue', 'aggrLevel',\n",
       "       'cmdCode', 'cmdDescE', 'cstCode', 'cstDesc', 'estCode', 'motCode',\n",
       "       'motDesc', 'period', 'periodDesc', 'pfCode', 'pt3ISO', 'pt3ISO2',\n",
       "       'ptCode', 'ptCode2', 'ptTitle', 'ptTitle2', 'qtAltCode', 'qtAltDesc',\n",
       "       'qtCode', 'qtDesc', 'rgCode', 'rgDesc', 'rt3ISO', 'rtCode', 'rtTitle',\n",
       "       'yr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yr</th>\n",
       "      <th>NetWeight</th>\n",
       "      <th>TradeValue</th>\n",
       "      <th>aggrLevel</th>\n",
       "      <th>cmdCode</th>\n",
       "      <th>cmdDescE</th>\n",
       "      <th>period</th>\n",
       "      <th>rgDesc</th>\n",
       "      <th>rtTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>190590</td>\n",
       "      <td>Food preparations; bakers' wares n.e.s. in hea...</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>Preparations of cereals, flour, starch or milk...</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>1905</td>\n",
       "      <td>Bread, pastry, cakes, biscuits, other bakers' ...</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>60</td>\n",
       "      <td>92</td>\n",
       "      <td>4</td>\n",
       "      <td>8541</td>\n",
       "      <td>Diodes, transistors, similar semiconductor dev...</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>20</td>\n",
       "      <td>92</td>\n",
       "      <td>4</td>\n",
       "      <td>8513</td>\n",
       "      <td>Lamps; portable, electric, designed to functio...</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>60</td>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>854140</td>\n",
       "      <td>Electrical apparatus; photosensitive, includin...</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>Electrical machinery and equipment and parts t...</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018</td>\n",
       "      <td>20</td>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>851310</td>\n",
       "      <td>Lamps; portable, electric, designed to functio...</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>6</td>\n",
       "      <td>999999</td>\n",
       "      <td>Commodities not specified according to kind</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>4</td>\n",
       "      <td>9999</td>\n",
       "      <td>Commodities not specified according to kind</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>1062</td>\n",
       "      <td>0</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>All Commodities</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>Toys, games and sports requisites; parts and a...</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>950699</td>\n",
       "      <td>Equipment for outdoor games and recreation n.e...</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>9506</td>\n",
       "      <td>Gymnastics, athletics, other sports (including...</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>Commodities not specified according to kind</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>758</td>\n",
       "      <td>6</td>\n",
       "      <td>999999</td>\n",
       "      <td>Commodities not specified according to kind</td>\n",
       "      <td>201811</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>758</td>\n",
       "      <td>4</td>\n",
       "      <td>9999</td>\n",
       "      <td>Commodities not specified according to kind</td>\n",
       "      <td>201811</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>664</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>Man-made filaments</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018</td>\n",
       "      <td>70</td>\n",
       "      <td>664</td>\n",
       "      <td>4</td>\n",
       "      <td>5407</td>\n",
       "      <td>Woven fabrics of synthetic filament yarn, incl...</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>758</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>Commodities not specified according to kind</td>\n",
       "      <td>201811</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>758</td>\n",
       "      <td>0</td>\n",
       "      <td>TOTAL</td>\n",
       "      <td>All Commodities</td>\n",
       "      <td>201811</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018</td>\n",
       "      <td>70</td>\n",
       "      <td>664</td>\n",
       "      <td>6</td>\n",
       "      <td>540710</td>\n",
       "      <td>Fabrics, woven; from high tenacity yarn, of ny...</td>\n",
       "      <td>201812</td>\n",
       "      <td>Imports</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      yr  NetWeight  TradeValue  aggrLevel cmdCode  \\\n",
       "0   2018         10          33          6  190590   \n",
       "1   2018          0          33          2      19   \n",
       "2   2018         10          33          4    1905   \n",
       "3   2018         60          92          4    8541   \n",
       "4   2018         20          92          4    8513   \n",
       "5   2018         60          92          6  854140   \n",
       "6   2018          0         184          2      85   \n",
       "7   2018         20          92          6  851310   \n",
       "8   2018          0         140          6  999999   \n",
       "9   2018          0         140          4    9999   \n",
       "10  2018          0        1062          0   TOTAL   \n",
       "11  2018          0          40          2      95   \n",
       "12  2018         10          40          6  950699   \n",
       "13  2018         10          40          4    9506   \n",
       "14  2018          0         140          2      99   \n",
       "15  2018          0         758          6  999999   \n",
       "16  2018          0         758          4    9999   \n",
       "17  2018          0         664          2      54   \n",
       "18  2018         70         664          4    5407   \n",
       "19  2018          0         758          2      99   \n",
       "20  2018          0         758          0   TOTAL   \n",
       "21  2018         70         664          6  540710   \n",
       "\n",
       "                                             cmdDescE  period   rgDesc  \\\n",
       "0   Food preparations; bakers' wares n.e.s. in hea...  201812  Imports   \n",
       "1   Preparations of cereals, flour, starch or milk...  201812  Imports   \n",
       "2   Bread, pastry, cakes, biscuits, other bakers' ...  201812  Imports   \n",
       "3   Diodes, transistors, similar semiconductor dev...  201812  Imports   \n",
       "4   Lamps; portable, electric, designed to functio...  201812  Imports   \n",
       "5   Electrical apparatus; photosensitive, includin...  201812  Imports   \n",
       "6   Electrical machinery and equipment and parts t...  201812  Imports   \n",
       "7   Lamps; portable, electric, designed to functio...  201812  Imports   \n",
       "8         Commodities not specified according to kind  201812  Imports   \n",
       "9         Commodities not specified according to kind  201812  Imports   \n",
       "10                                    All Commodities  201812  Imports   \n",
       "11  Toys, games and sports requisites; parts and a...  201812  Imports   \n",
       "12  Equipment for outdoor games and recreation n.e...  201812  Imports   \n",
       "13  Gymnastics, athletics, other sports (including...  201812  Imports   \n",
       "14        Commodities not specified according to kind  201812  Imports   \n",
       "15        Commodities not specified according to kind  201811  Imports   \n",
       "16        Commodities not specified according to kind  201811  Imports   \n",
       "17                                 Man-made filaments  201812  Imports   \n",
       "18  Woven fabrics of synthetic filament yarn, incl...  201812  Imports   \n",
       "19        Commodities not specified according to kind  201811  Imports   \n",
       "20                                    All Commodities  201811  Imports   \n",
       "21  Fabrics, woven; from high tenacity yarn, of ny...  201812  Imports   \n",
       "\n",
       "     rtTitle  \n",
       "0   Zimbabwe  \n",
       "1   Zimbabwe  \n",
       "2   Zimbabwe  \n",
       "3   Zimbabwe  \n",
       "4   Zimbabwe  \n",
       "5   Zimbabwe  \n",
       "6   Zimbabwe  \n",
       "7   Zimbabwe  \n",
       "8   Zimbabwe  \n",
       "9   Zimbabwe  \n",
       "10  Zimbabwe  \n",
       "11  Zimbabwe  \n",
       "12  Zimbabwe  \n",
       "13  Zimbabwe  \n",
       "14  Zimbabwe  \n",
       "15  Zimbabwe  \n",
       "16  Zimbabwe  \n",
       "17  Zimbabwe  \n",
       "18  Zimbabwe  \n",
       "19  Zimbabwe  \n",
       "20  Zimbabwe  \n",
       "21  Zimbabwe  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f)[['yr','NetWeight','TradeValue','aggrLevel','cmdCode','cmdDescE','period','rgDesc','rtTitle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
